{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import re\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import yake\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import normalize, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/rajkhera/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/rajkhera/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/rajkhera/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/rajkhera/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2))  # Bigrams included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_learn_image_detect = \"Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers - 8Ã— deeper than VGG nets [40] but still having lower complexity. An ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC & COCO 2015 competitions1, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.\"\n",
    "math_theory_of_comm = \"The recent development of various methods of modulation such as PCM and PPM which exchange bandwidth for signal-to-noise ratio has intensified the interest in a general theory of communication. A basis for such a theory is contained in the important papers of Nyquist 1 and Hartley 2 on this subject. In the present paper we will extend the theory to include a number of new factors, in particular the effect of noise in the channel, and the savings possible due to the statistical structure of the original message and due to the nature of the final destination of the information.\"\n",
    "auto_licenseplate_recog_img_process = \"A vehicle license plate recognition system is an important proficiency that could be used for identification of engine vehicle all over the earth. It is valuable in numerous applications such as entrance admission, security, parking control, road traffic control, and speed control. However, the system only manages to identify the license number and needs an operator to control the collected data. Therefore, this paper proposes an automatic license plate recognition system by using the image processing and template matching approach. The current study aims to increase the efficiency of license plate recognition system for Universiti Malaysia Perlis (UniMAP) smart university. This venture comprises of simulation program to recognize license plate characters where a captured image of vehicles will be the input. Then, these images will be processed using several image processing techniques and optical character recognition method in order to recognize the segmented number plate. The image processing techniques consist of colour conversion, image segmentation using Otsu's thresholding, noise removal, image subtraction, image cropping and bounding box feature. The optical character recognition based on template matching approach is used to analyse the printed characters on the segmented license plate image and to produce an output data consisting of characters. Overall, the proposed automatic vehicle license plate recognition system is capable to perform the recognition process by successfully recognizing license plate of 13 cars, from a total of 14 cars.\"\n",
    "stats_rand_signals = \"The autocorrelation and power spectral density functions of a random process are two of the most commonly used concepts in signal processing and in its applications. The relations that define them involve the expected value of a double product of the process or of its Fourier transform. Hence, they are based on second-order statistics. The generalization of this idea leads to the so-called cumulant functions and cumulant spectra, therefore higher-order statistics. Theoretically, the higher-order statistics are null for Gaussian signals. Practically, these quantities are not vanishing. In this paper the third-order statistics for different types of random signals are analyzed.\"\n",
    "matplotlib_2dgraphics = \"Matplotlib is a 2D graphics package used for Python for application development, interactive scripting,and publication-quality image generation across user interfaces and operating systems\"\n",
    "neural_networks_quantization_refine = \"Deploying neural networks (NNs) in low-resource domains is challenging because of their high computing, memory, and power requirements. For this reason, NNs are often quantized before deployment, but such an approach degrades their accuracy. Thus, we propose the counterexample-guided neural network quantization refinement (CEG4N) framework, which combines search-based quantization and equivalence checking. The former minimizes computational requirements, while the latter guarantees that the behavior of an NN does not change after quantization. We evaluate CEG4N on a diverse set of benchmarks, including large and small NNs. Our technique successfully quantizes the networks in the chosen evaluation set, while producing models with up to 163% better accuracy than state-of-the-art techniques.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Replace hyphens with space\n",
    "    text = text.replace('-', ' ')\n",
    "\n",
    "    # Remove punctuation and special characters\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "    # Remove numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = re.sub(r'\\b\\w*\\d+\\w*\\b', '', text)\n",
    "    \n",
    "    # Tokenize text\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stop words\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # Lemmatize tokens\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    \n",
    "    # Reassemble text\n",
    "    preprocessed_text = ' '.join(tokens)\n",
    "    \n",
    "    return preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rajkhera/Book-Recommendations-1/.venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Score: 1.0000\n",
      "Original Abstract: Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers - 8Ã— deeper than VGG nets [40] but still having lower complexity. An ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC & COCO 2015 competitions1, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.\n",
      "Preprocessed Abstract: deeper neural network difficult train present residual learning framework ease training network substantially deeper used previously explicitly reformulate layer learning residual function reference layer input instead learning unreferenced function provide comprehensive empirical evidence showing residual network easier optimize gain accuracy considerably increased depth imagenet dataset evaluate residual net depth layer deeper vgg net still lower complexity ensemble residual net achieves error imagenet test set result st place ilsvrc classification task also present analysis cifar layer depth representation central importance many visual recognition task solely due extremely deep representation obtain relative improvement coco object detection dataset deep residual net foundation submission ilsvrc coco competition also st place task imagenet detection imagenet localization coco detection coco segmentation\n",
      "\n",
      "Similarity Score: 0.3941\n",
      "Original Abstract: Deploying neural networks (NNs) in low-resource domains is challenging because of their high computing, memory, and power requirements. For this reason, NNs are often quantized before deployment, but such an approach degrades their accuracy. Thus, we propose the counterexample-guided neural network quantization refinement (CEG4N) framework, which combines search-based quantization and equivalence checking. The former minimizes computational requirements, while the latter guarantees that the behavior of an NN does not change after quantization. We evaluate CEG4N on a diverse set of benchmarks, including large and small NNs. Our technique successfully quantizes the networks in the chosen evaluation set, while producing models with up to 163% better accuracy than state-of-the-art techniques.\n",
      "Preprocessed Abstract: deploying neural network nns low resource domain challenging high computing memory power requirement reason nns often quantized deployment approach degrades accuracy thus propose counterexample guided neural network quantization refinement cegn framework combine search based quantization equivalence checking former minimizes computational requirement latter guarantee behavior nn change quantization evaluate cegn diverse set benchmark including large small nns technique successfully quantizes network chosen evaluation set producing model better accuracy state art technique\n",
      "\n",
      "Similarity Score: 0.1934\n",
      "Original Abstract: A vehicle license plate recognition system is an important proficiency that could be used for identification of engine vehicle all over the earth. It is valuable in numerous applications such as entrance admission, security, parking control, road traffic control, and speed control. However, the system only manages to identify the license number and needs an operator to control the collected data. Therefore, this paper proposes an automatic license plate recognition system by using the image processing and template matching approach. The current study aims to increase the efficiency of license plate recognition system for Universiti Malaysia Perlis (UniMAP) smart university. This venture comprises of simulation program to recognize license plate characters where a captured image of vehicles will be the input. Then, these images will be processed using several image processing techniques and optical character recognition method in order to recognize the segmented number plate. The image processing techniques consist of colour conversion, image segmentation using Otsu's thresholding, noise removal, image subtraction, image cropping and bounding box feature. The optical character recognition based on template matching approach is used to analyse the printed characters on the segmented license plate image and to produce an output data consisting of characters. Overall, the proposed automatic vehicle license plate recognition system is capable to perform the recognition process by successfully recognizing license plate of 13 cars, from a total of 14 cars.\n",
      "Preprocessed Abstract: vehicle license plate recognition system important proficiency could used identification engine vehicle earth valuable numerous application entrance admission security parking control road traffic control speed control however system manages identify license number need operator control collected data therefore paper proposes automatic license plate recognition system using image processing template matching approach current study aim increase efficiency license plate recognition system universiti malaysia perlis unimap smart university venture comprises simulation program recognize license plate character captured image vehicle input image processed using several image processing technique optical character recognition method order recognize segmented number plate image processing technique consist colour conversion image segmentation using otsus thresholding noise removal image subtraction image cropping bounding box feature optical character recognition based template matching approach used analyse printed character segmented license plate image produce output data consisting character overall proposed automatic vehicle license plate recognition system capable perform recognition process successfully recognizing license plate car total car\n",
      "\n",
      "Similarity Score: 0.0741\n",
      "Original Abstract: Matplotlib is a 2D graphics package used for Python for application development, interactive scripting,and publication-quality image generation across user interfaces and operating systems\n",
      "Preprocessed Abstract: matplotlib graphic package used python application development interactive scriptingand publication quality image generation across user interface operating system\n",
      "\n",
      "Similarity Score: 0.0466\n",
      "Original Abstract: The autocorrelation and power spectral density functions of a random process are two of the most commonly used concepts in signal processing and in its applications. The relations that define them involve the expected value of a double product of the process or of its Fourier transform. Hence, they are based on second-order statistics. The generalization of this idea leads to the so-called cumulant functions and cumulant spectra, therefore higher-order statistics. Theoretically, the higher-order statistics are null for Gaussian signals. Practically, these quantities are not vanishing. In this paper the third-order statistics for different types of random signals are analyzed.\n",
      "Preprocessed Abstract: autocorrelation power spectral density function random process two commonly used concept signal processing application relation define involve expected value double product process fourier transform hence based second order statistic generalization idea lead called cumulant function cumulant spectrum therefore higher order statistic theoretically higher order statistic null gaussian signal practically quantity vanishing paper third order statistic different type random signal analyzed\n",
      "\n",
      "Similarity Score: -0.0069\n",
      "Original Abstract: The recent development of various methods of modulation such as PCM and PPM which exchange bandwidth for signal-to-noise ratio has intensified the interest in a general theory of communication. A basis for such a theory is contained in the important papers of Nyquist 1 and Hartley 2 on this subject. In the present paper we will extend the theory to include a number of new factors, in particular the effect of noise in the channel, and the savings possible due to the statistical structure of the original message and due to the nature of the final destination of the information.\n",
      "Preprocessed Abstract: recent development various method modulation pcm ppm exchange bandwidth signal noise ratio intensified interest general theory communication basis theory contained important paper nyquist hartley subject present paper extend theory include number new factor particular effect noise channel saving possible due statistical structure original message due nature final destination information\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def compute_embeddings(texts):\n",
    "\n",
    "    preprocessed_texts = [preprocess_text(text) for text in texts]\n",
    "\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform(preprocessed_texts)\n",
    "    \n",
    "    # Convert to embeddings using SentenceTransformer\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    embeddings = model.encode(preprocessed_texts, convert_to_tensor=True)\n",
    "    return embeddings.cpu().numpy()  # Ensure embeddings are on CPU and convert to NumPy array\n",
    "\n",
    "def get_similarities(embedding, embeddings):\n",
    "\n",
    "    return cosine_similarity([embedding], embeddings)[0]\n",
    "\n",
    "def rank_abstracts(query_abstract, abstracts):\n",
    "\n",
    "    # Preprocess texts\n",
    "    preprocessed_abstracts = [preprocess_text(text) for text in abstracts]\n",
    "    preprocessed_query_abstract = preprocess_text(query_abstract)\n",
    "    \n",
    "    # Compute embeddings\n",
    "    all_embeddings = compute_embeddings(abstracts)\n",
    "    query_embedding = compute_embeddings([query_abstract])[0]\n",
    "    \n",
    "    # Compute similarities\n",
    "    similarities = get_similarities(query_embedding, all_embeddings)\n",
    "\n",
    "    # Get indices of abstracts sorted by similarity\n",
    "    ranked_indices = np.argsort(similarities)[::-1]\n",
    "    \n",
    "    # Return both original and preprocessed abstracts along with similarity scores\n",
    "    return [\n",
    "        (abstracts[i], preprocessed_abstracts[i], similarities[i]) \n",
    "        for i in ranked_indices\n",
    "    ]\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # List of research paper abstracts\n",
    "    abstracts = [\n",
    "        deep_learn_image_detect, math_theory_of_comm, auto_licenseplate_recog_img_process, stats_rand_signals, matplotlib_2dgraphics, neural_networks_quantization_refine\n",
    "    ]\n",
    "\n",
    "    # Query abstract\n",
    "    query_abstract = deep_learn_image_detect\n",
    "    \n",
    "    # Get ranked abstracts\n",
    "    ranked_abstracts = rank_abstracts(query_abstract, abstracts)\n",
    "    \n",
    "    # Print results\n",
    "    for original, preprocessed, score in ranked_abstracts:\n",
    "        print(f\"Similarity Score: {score:.4f}\")\n",
    "        print(f\"Original Abstract: {original}\")\n",
    "        print(f\"Preprocessed Abstract: {preprocessed}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/rajkhera/Book-Recommendations-1/Webscraping/publications.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n",
      "\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/Users/rajkhera/Book-Recommendations-1/Webscraping/publications.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/Book-Recommendations-1/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n",
      "\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n",
      "\u001b[1;32m   1014\u001b[0m     dialect,\n",
      "\u001b[1;32m   1015\u001b[0m     delimiter,\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n",
      "\u001b[1;32m   1023\u001b[0m )\n",
      "\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n",
      "\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/Book-Recommendations-1/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n",
      "\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n",
      "\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n",
      "\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n",
      "\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\n",
      "File \u001b[0;32m~/Book-Recommendations-1/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n",
      "\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/Book-Recommendations-1/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n",
      "\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "\n",
      "File \u001b[0;32m~/Book-Recommendations-1/.venv/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n",
      "\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n",
      "\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n",
      "\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n",
      "\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n",
      "\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n",
      "\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n",
      "\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/rajkhera/Book-Recommendations-1/Webscraping/publications.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"/Users/rajkhera/Book-Recommendations-1/Webscraping/publications.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Year</th>\n",
       "      <th>Journal/Conference Name</th>\n",
       "      <th>Conference or Journal</th>\n",
       "      <th>Publisher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Deep Residual Learning for Image Recognition</td>\n",
       "      <td>Xiangyu Zhang, Shaoqing Ren, Jian Sun, Kaiming He</td>\n",
       "      <td>Deeper neural networks are more difficult to t...</td>\n",
       "      <td>2016</td>\n",
       "      <td>2016 IEEE Conference on Computer Vision and Pa...</td>\n",
       "      <td>Conference Paper</td>\n",
       "      <td>IEEE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A mathematical theory of communication</td>\n",
       "      <td>C. E. Shannon</td>\n",
       "      <td>The recent development of various methods of m...</td>\n",
       "      <td>1948</td>\n",
       "      <td>The Bell System Technical Journal</td>\n",
       "      <td>Journal Article</td>\n",
       "      <td>Nokia Bell Labs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A new look at the statistical model identifica...</td>\n",
       "      <td>H. Akaike</td>\n",
       "      <td>The history of the development of statistical ...</td>\n",
       "      <td>1974</td>\n",
       "      <td>IEEE Transactions on Automatic Control</td>\n",
       "      <td>Journal Article</td>\n",
       "      <td>IEEE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Image quality assessment: from error visibilit...</td>\n",
       "      <td>H.R. Sheikh, A.C. Bovik, Zhou Wang, E.P. Simon...</td>\n",
       "      <td>Objective methods for assessing perceptual ima...</td>\n",
       "      <td>2004</td>\n",
       "      <td>IEEE Transactions on Image Processing</td>\n",
       "      <td>Journal Article</td>\n",
       "      <td>IEEE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gradient-based learning applied to document re...</td>\n",
       "      <td>Y. Bengio, Y. Lecun, P. Haffner, L. Bottou</td>\n",
       "      <td>Multilayer neural networks trained with the ba...</td>\n",
       "      <td>1998</td>\n",
       "      <td>Proceedings of the IEEE</td>\n",
       "      <td>Journal Article</td>\n",
       "      <td>IEEE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0       Deep Residual Learning for Image Recognition   \n",
       "1             A mathematical theory of communication   \n",
       "2  A new look at the statistical model identifica...   \n",
       "3  Image quality assessment: from error visibilit...   \n",
       "4  Gradient-based learning applied to document re...   \n",
       "\n",
       "                                              Author  \\\n",
       "0  Xiangyu Zhang, Shaoqing Ren, Jian Sun, Kaiming He   \n",
       "1                                      C. E. Shannon   \n",
       "2                                          H. Akaike   \n",
       "3  H.R. Sheikh, A.C. Bovik, Zhou Wang, E.P. Simon...   \n",
       "4         Y. Bengio, Y. Lecun, P. Haffner, L. Bottou   \n",
       "\n",
       "                                            Abstract  Year  \\\n",
       "0  Deeper neural networks are more difficult to t...  2016   \n",
       "1  The recent development of various methods of m...  1948   \n",
       "2  The history of the development of statistical ...  1974   \n",
       "3  Objective methods for assessing perceptual ima...  2004   \n",
       "4  Multilayer neural networks trained with the ba...  1998   \n",
       "\n",
       "                             Journal/Conference Name Conference or Journal  \\\n",
       "0  2016 IEEE Conference on Computer Vision and Pa...      Conference Paper   \n",
       "1                  The Bell System Technical Journal       Journal Article   \n",
       "2             IEEE Transactions on Automatic Control       Journal Article   \n",
       "3              IEEE Transactions on Image Processing       Journal Article   \n",
       "4                            Proceedings of the IEEE       Journal Article   \n",
       "\n",
       "         Publisher  \n",
       "0             IEEE  \n",
       "1  Nokia Bell Labs  \n",
       "2             IEEE  \n",
       "3             IEEE  \n",
       "4             IEEE  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_list = df['Title'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Deep Residual Learning for Image Recognition',\n",
       " 'A mathematical theory of communication',\n",
       " 'A new look at the statistical model identification',\n",
       " 'Image quality assessment: from error visibility to structural similarity',\n",
       " 'Gradient-based learning applied to document recognition',\n",
       " 'ImageNet: A large-scale hierarchical image database',\n",
       " 'A fast and elitist multiobjective genetic algorithm: NSGA-II',\n",
       " 'Particle swarm optimization',\n",
       " 'Going deeper with convolutions',\n",
       " 'You Only Look Once: Unified, Real-Time Object Detection',\n",
       " 'Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks',\n",
       " 'Densely Connected Convolutional Networks',\n",
       " 'Fully convolutional networks for semantic segmentation',\n",
       " 'Compressed sensing',\n",
       " 'A Computational Approach to Edge Detection',\n",
       " 'Long Short-Term Memory',\n",
       " 'Fast R-CNN',\n",
       " 'Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation',\n",
       " 'Mask R-CNN',\n",
       " 'Histograms of oriented gradients for human detection',\n",
       " 'Textural Features for Image Classification',\n",
       " 'Squeeze-and-Excitation Networks',\n",
       " 'Rethinking the Inception Architecture for Computer Vision',\n",
       " 'Feature Pyramid Networks for Object Detection',\n",
       " 'A theory for multiresolution signal decomposition: the wavelet representation',\n",
       " 'Fuzzy identification of systems and its applications to modeling and control',\n",
       " 'A Survey on Transfer Learning',\n",
       " 'A tutorial on hidden Markov models and selected applications in speech recognition',\n",
       " 'Focal Loss for Dense Object Detection',\n",
       " 'MobileNetV2: Inverted Residuals and Linear Bottlenecks',\n",
       " 'DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs',\n",
       " 'A method for registration of 3-D shapes',\n",
       " 'Stochastic Relaxation, Gibbs Distributions, and the Bayesian Restoration of Images',\n",
       " 'ANFIS: adaptive-network-based fuzzy inference system',\n",
       " 'Unpaired Image-to-Image Translation Using Cycle-Consistent Adversarial Networks',\n",
       " 'Multiresolution gray-scale and rotation invariant texture classification with local binary patterns',\n",
       " 'SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation',\n",
       " 'Robust uncertainty principles: exact signal reconstruction from highly incomplete frequency information',\n",
       " 'Image-to-Image Translation with Conditional Adversarial Networks',\n",
       " 'YOLO9000: Better, Faster, Stronger',\n",
       " 'Swin Transformer: Hierarchical Vision Transformer using Shifted Windows',\n",
       " 'Multiple emitter location and signal parameter estimation',\n",
       " 'Consensus problems in networks of agents with switching topology and time-delays',\n",
       " 'Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification',\n",
       " 'Cooperative diversity in wireless networks: Efficient protocols and outage behavior',\n",
       " 'A flexible new technique for camera calibration',\n",
       " \"Numerical solution of initial boundary value problems involving maxwell's equations in isotropic media\",\n",
       " 'Normalized cuts and image segmentation',\n",
       " 'A simple transmit diversity technique for wireless communications',\n",
       " 'Nearest neighbor pattern classification',\n",
       " 'Least squares quantization in PCM',\n",
       " 'Object recognition from local scale-invariant features',\n",
       " 'Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization',\n",
       " 'Cognitive radio: brain-empowered wireless communications',\n",
       " 'Rapid object detection using a boosted cascade of simple features',\n",
       " 'Xception: Deep Learning with Depthwise Separable Convolutions',\n",
       " 'No free lunch theorems for optimization',\n",
       " 'New directions in cryptography',\n",
       " 'Eigenfaces vs. Fisherfaces: recognition using class specific linear projection',\n",
       " 'Scale-space and edge detection using anisotropic diffusion',\n",
       " 'A model of saliency-based visual attention for rapid scene analysis',\n",
       " 'A tutorial on particle filters for online nonlinear/non-Gaussian Bayesian tracking',\n",
       " 'Mean shift: a robust approach toward feature space analysis',\n",
       " 'Pyramid Scene Parsing Network',\n",
       " 'A new optimizer using particle swarm theory',\n",
       " 'FaceNet: A unified embedding for face recognition and clustering',\n",
       " 'Are we ready for autonomous driving? The KITTI vision benchmark suite',\n",
       " 'Consensus and Cooperation in Networked Multi-Agent Systems',\n",
       " 'Ant system: optimization by a colony of cooperating agents',\n",
       " 'The use of fast Fourier transform for the estimation of power spectra: A method based on time averaging over short, modified periodograms',\n",
       " 'Active contours without edges',\n",
       " 'Representation Learning: A Review and New Perspectives',\n",
       " 'Robust Face Recognition via Sparse Representation',\n",
       " 'Sensitive measurement of optical nonlinearities using a single beam',\n",
       " 'An application-specific protocol architecture for wireless microsensor networks',\n",
       " 'K-SVD: An algorithm for designing overcomplete dictionaries for sparse representation',\n",
       " 'Memristor-The missing circuit element',\n",
       " 'Petri nets: Properties, analysis and applications',\n",
       " 'Feature selection based on mutual information criteria of max-dependency, max-relevance, and min-redundancy',\n",
       " 'Object Detection with Discriminatively Trained Part-Based Models',\n",
       " 'Energy-efficient communication protocol for wireless microsensor networks',\n",
       " 'Signal Recovery From Random Measurements Via Orthogonal Matching Pursuit',\n",
       " 'Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition',\n",
       " 'Magnetism from conductors and enhanced nonlinear phenomena',\n",
       " 'A Formal Basis for the Heuristic Determination of Minimum Cost Paths',\n",
       " 'The Cityscapes Dataset for Semantic Urban Scene Understanding',\n",
       " 'De-noising by soft-thresholding',\n",
       " 'SLIC Superpixels Compared to State-of-the-Art Superpixel Methods',\n",
       " 'Matching pursuits with time-frequency dictionaries',\n",
       " 'Coordination of groups of mobile autonomous agents using nearest neighbor rules',\n",
       " 'Creating the CIPRES Science Gateway for inference of large phylogenetic trees',\n",
       " 'Toward the next generation of recommender systems: a survey of the state-of-the-art and possible extensions',\n",
       " 'Overview of the H.264/AVC video coding standard',\n",
       " 'MOEA/D: A Multiobjective Evolutionary Algorithm Based on Decomposition',\n",
       " 'The particle swarm - explosion, stability, and convergence in a multidimensional complex space',\n",
       " 'Performance analysis of the IEEE 802.11 distributed coordination function',\n",
       " 'Reinforcement Learning: An Introduction',\n",
       " 'ORB: An efficient alternative to SIFT or SURF',\n",
       " 'Non-local Neural Networks',\n",
       " 'Image Denoising by Sparse 3-D Transform-Domain Collaborative Filtering']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "title_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
