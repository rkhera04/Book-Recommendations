{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_webdriver():\n",
    "    options = webdriver.ChromeOptions()\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_page_source(driver, url):\n",
    "    driver.get(url)\n",
    "    try:\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, 'List-results-items'))\n",
    "        )\n",
    "        return driver.page_source\n",
    "    except TimeoutException:\n",
    "        print(f\"Timeout while waiting for page to load: {url}\")\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_articles(soup):\n",
    "    articles_data = {}\n",
    "    content = soup.find('xpl-results-list')\n",
    "    articles = content.find_all('div', class_=\"List-results-items\")\n",
    "    author_names = []\n",
    "    for article in articles:\n",
    "        title_element = article.find('a')\n",
    "        title = title_element.text\n",
    "        link = title_element.attrs['href']\n",
    "        \n",
    "        year_span = article.find('span', string=lambda t: t and 'Year:' in t)\n",
    "        year = year_span.text.split(': ')[1] if year_span else 'Year not found'\n",
    "        \n",
    "        conference_title = article.find('div', class_='description text-base-md-lh').a.string.strip()\n",
    "        \n",
    "        conference_paper_span = article.find('span', string=lambda text: text and 'Conference Paper' in text)\n",
    "        journal_article_span = article.find('span', string=lambda text: text and 'Journal Article' in text)\n",
    "        paper_type = conference_paper_span.string if conference_paper_span else (journal_article_span.string if journal_article_span else 'Unknown')\n",
    "        \n",
    "        publisher_span = article.find('span', string=lambda text: text and 'Publisher:' in text)\n",
    "        publisher_span_text = publisher_span.find_next_sibling('span') \n",
    "        publisher = publisher_span_text.text.strip() if publisher_span_text else 'Publisher not found'\n",
    "\n",
    "        author_names = [author.find('span').text.strip() for author in article.find_all('a', target=\"_self\")]\n",
    "        authors = article.find_all('a', target=\"_self\")\n",
    "        if authors == []:\n",
    "            authors = article.find_all('button', {'xplhighlight' : True})\n",
    "            year = article.find('span', string=lambda t: t and 'Year:' in t).text.split(': ')[1]\n",
    "        for author in authors:\n",
    "            author_names.append(author.find('span').text.strip())\n",
    "        articles_data[title] = [\n",
    "            \"https://ieeexplore.ieee.org\" + link,\n",
    "            list(set(author_names)),\n",
    "            year,\n",
    "            conference_title,\n",
    "            paper_type,\n",
    "            publisher\n",
    "        ]\n",
    "        author_names = []\n",
    "    return articles_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTitles(end_page):\n",
    "    driver = setup_webdriver()\n",
    "    result = {}\n",
    "    \n",
    "    for i in range(1, end_page):\n",
    "        url = f\"https://ieeexplore.ieee.org/search/searchresult.jsp?action=search&highlight=true&returnType=SEARCH&matchPubs=true&rowsPerPage=10&refinements=ContentType:Conferences&refinements=ContentType:Journals&returnFacets=ALL&pageNumber={i}\"\n",
    "        page_source = fetch_page_source(driver, url)\n",
    "        \n",
    "        if page_source:\n",
    "            soup = BeautifulSoup(page_source, 'html.parser')\n",
    "            articles_data = parse_articles(soup)\n",
    "            result.update(articles_data)\n",
    "    \n",
    "    driver.quit()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_and_info = getTitles(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Deep Residual Learning for Image Recognition': ['https://ieeexplore.ieee.org/document/7780459/',\n",
       "  ['Shaoqing Ren', 'Xiangyu Zhang', 'Kaiming He', 'Jian Sun'],\n",
       "  '2016',\n",
       "  '2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)',\n",
       "  'Conference Paper',\n",
       "  'IEEE'],\n",
       " 'A mathematical theory of communication': ['https://ieeexplore.ieee.org/document/6773024/',\n",
       "  ['C. E. Shannon'],\n",
       "  '1948',\n",
       "  'The Bell System Technical Journal',\n",
       "  'Journal Article',\n",
       "  'Nokia Bell Labs'],\n",
       " 'A new look at the statistical model identification': ['https://ieeexplore.ieee.org/document/1100705/',\n",
       "  ['H. Akaike'],\n",
       "  '1974',\n",
       "  'IEEE Transactions on Automatic Control',\n",
       "  'Journal Article',\n",
       "  'IEEE'],\n",
       " 'Image quality assessment: from error visibility to structural similarity': ['https://ieeexplore.ieee.org/document/1284395/',\n",
       "  ['E.P. Simoncelli', 'Zhou Wang', 'H.R. Sheikh', 'A.C. Bovik'],\n",
       "  '2004',\n",
       "  'IEEE Transactions on Image Processing',\n",
       "  'Journal Article',\n",
       "  'IEEE'],\n",
       " 'Gradient-based learning applied to document recognition': ['https://ieeexplore.ieee.org/document/726791/',\n",
       "  ['L. Bottou', 'Y. Bengio', 'P. Haffner', 'Y. Lecun'],\n",
       "  '1998',\n",
       "  'Proceedings of the IEEE',\n",
       "  'Journal Article',\n",
       "  'IEEE'],\n",
       " 'ImageNet: A large-scale hierarchical image database': ['https://ieeexplore.ieee.org/document/5206848/',\n",
       "  ['Wei Dong',\n",
       "   'Kai Li',\n",
       "   'Richard Socher',\n",
       "   'Li-Jia Li',\n",
       "   'Li Fei-Fei',\n",
       "   'Jia Deng'],\n",
       "  '2009',\n",
       "  '2009 IEEE Conference on Computer Vision and Pattern Recognition',\n",
       "  'Conference Paper',\n",
       "  'IEEE'],\n",
       " 'A fast and elitist multiobjective genetic algorithm: NSGA-II': ['https://ieeexplore.ieee.org/document/996017/',\n",
       "  ['K. Deb', 'T. Meyarivan', 'A. Pratap', 'S. Agarwal'],\n",
       "  '2002',\n",
       "  'IEEE Transactions on Evolutionary Computation',\n",
       "  'Journal Article',\n",
       "  'IEEE'],\n",
       " 'Particle swarm optimization': ['https://ieeexplore.ieee.org/document/488968/',\n",
       "  ['J. Kennedy', 'R. Eberhart'],\n",
       "  '1995',\n",
       "  \"Proceedings of ICNN'95 - International Conference on Neural Networks\",\n",
       "  'Conference Paper',\n",
       "  'IEEE'],\n",
       " 'Going deeper with convolutions': ['https://ieeexplore.ieee.org/document/7298594/',\n",
       "  ['Dumitru Erhan',\n",
       "   'Yangqing Jia',\n",
       "   'Scott Reed',\n",
       "   'Andrew Rabinovich',\n",
       "   'Wei Liu',\n",
       "   'Pierre Sermanet',\n",
       "   'Christian Szegedy',\n",
       "   'Dragomir Anguelov',\n",
       "   'Vincent Vanhoucke'],\n",
       "  '2015',\n",
       "  '2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)',\n",
       "  'Conference Paper',\n",
       "  'IEEE'],\n",
       " 'You Only Look Once: Unified, Real-Time Object Detection': ['https://ieeexplore.ieee.org/document/7780460/',\n",
       "  ['Joseph Redmon', 'Ross Girshick', 'Santosh Divvala', 'Ali Farhadi'],\n",
       "  '2016',\n",
       "  '2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)',\n",
       "  'Conference Paper',\n",
       "  'IEEE']}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles_and_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getInfo(paper_dict):\n",
    "    options = webdriver.ChromeOptions()\n",
    "    # Launch Chrome:\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    result = {}\n",
    "    \n",
    "    for paper_title, paper_info in paper_dict.items():\n",
    "        url = paper_info[0]  # Extract the URL from the dictionary\n",
    "        driver.get(url)\n",
    "        \n",
    "        try:\n",
    "            WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located(\n",
    "                    (By.CLASS_NAME, 'u-mb-1')  # Adjust this if necessary for the correct class\n",
    "                )\n",
    "            )\n",
    "        except TimeoutException:\n",
    "            print(f\"Timeout while waiting for abstract to load on {url}\")\n",
    "            continue\n",
    "        \n",
    "        page_source = driver.page_source\n",
    "        soup = BeautifulSoup(page_source, 'html.parser')\n",
    "        dynamic_content = soup.find('div', {'xplmathjax': True})\n",
    "        \n",
    "        if dynamic_content:\n",
    "            result[paper_title] = dynamic_content.get_text(strip=True)\n",
    "        else:\n",
    "            result[paper_title] = \"No abstract found\"\n",
    "    \n",
    "    driver.quit()\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_page(driver, url):\n",
    "    driver.get(url)\n",
    "    try:\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, 'u-mb-1'))\n",
    "        )\n",
    "        return driver.page_source\n",
    "    except TimeoutException:\n",
    "        print(f\"Timeout while waiting for abstract to load on {url}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_abstract(soup):\n",
    "    dynamic_content = soup.find('div', {'xplmathjax': True})\n",
    "    if dynamic_content:\n",
    "        return dynamic_content.get_text(strip=True)\n",
    "    else:\n",
    "        return \"No abstract found\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getInfo(paper_dict):\n",
    "    driver = setup_webdriver()\n",
    "    result = {}\n",
    "    \n",
    "    for paper_title, paper_info in paper_dict.items():\n",
    "        url = paper_info[0]  # Extract the URL from the dictionary\n",
    "        page_source = load_page(driver, url)\n",
    "        \n",
    "        if page_source:\n",
    "            soup = BeautifulSoup(page_source, 'html.parser')\n",
    "            abstract = extract_abstract(soup)\n",
    "            result[paper_title] = abstract\n",
    "    \n",
    "    driver.quit()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstracts_test = getInfo(titles_and_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Deep Residual Learning for Image Recognition': 'Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers - 8× deeper than VGG nets [40] but still having lower complexity. An ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC & COCO 2015 competitions1, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.',\n",
       " 'A mathematical theory of communication': 'The recent development of various methods of modulation such as PCM and PPM which exchange bandwidth for signal-to-noise ratio has intensified the interest in a general theory of communication. A basis for such a theory is contained in the important papers of Nyquist1and Hartley2on this subject. In the present paper we will extend the theory to include a number of new factors, in particular the effect of noise in the channel, and the savings possible due to the statistical structure of the original message and due to the nature of the final destination of the information.',\n",
       " 'A new look at the statistical model identification': 'The history of the development of statistical hypothesis testing in time series analysis is reviewed briefly and it is pointed out that the hypothesis testing procedure is not adequately defined as the procedure for statistical model identification. The classical maximum likelihood estimation procedure is reviewed and a new estimate minimum information theoretical criterion (AIC) estimate (MAICE) which is designed for the purpose of statistical identification is introduced. When there are several competing models the MAICE is defined by the model and the maximum likelihood estimates of the parameters which give the minimum of AIC defined by AIC = (-2)log-(maximum likelihood) + 2(number of independently adjusted parameters within the model). MAICE provides a versatile procedure for statistical model identification which is free from the ambiguities inherent in the application of conventional hypothesis testing procedure. The practical utility of MAICE in time series analysis is demonstrated with some numerical examples.',\n",
       " 'Image quality assessment: from error visibility to structural similarity': 'Objective methods for assessing perceptual image quality traditionally attempted to quantify the visibility of errors (differences) between a distorted image and a reference image using a variety of known properties of the human visual system. Under the assumption that human visual perception is highly adapted for extracting structural information from a scene, we introduce an alternative complementary framework for quality assessment based on the degradation of structural information. As a specific example of this concept, we develop a structural similarity index and demonstrate its promise through a set of intuitive examples, as well as comparison to both subjective ratings and state-of-the-art objective methods on a database of images compressed with JPEG and JPEG2000. A MATLAB implementation of the proposed algorithm is available online at http://www.cns.nyu.edu//spl sim/lcv/ssim/.',\n",
       " 'Gradient-based learning applied to document recognition': 'Multilayer neural networks trained with the back-propagation algorithm constitute the best example of a successful gradient based learning technique. Given an appropriate network architecture, gradient-based learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns, such as handwritten characters, with minimal preprocessing. This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task. Convolutional neural networks, which are specifically designed to deal with the variability of 2D shapes, are shown to outperform all other techniques. Real-life document recognition systems are composed of multiple modules including field extraction, segmentation recognition, and language modeling. A new learning paradigm, called graph transformer networks (GTN), allows such multimodule systems to be trained globally using gradient-based methods so as to minimize an overall performance measure. Two systems for online handwriting recognition are described. Experiments demonstrate the advantage of global training, and the flexibility of graph transformer networks. A graph transformer network for reading a bank cheque is also described. It uses convolutional neural network character recognizers combined with global training techniques to provide record accuracy on business and personal cheques. It is deployed commercially and reads several million cheques per day.',\n",
       " 'ImageNet: A large-scale hierarchical image database': 'The explosion of image data on the Internet has the potential to foster more sophisticated and robust models and algorithms to index, retrieve, organize and interact with images and multimedia data. But exactly how such data can be harnessed and organized remains a critical problem. We introduce here a new database called “ImageNet”, a large-scale ontology of images built upon the backbone of the WordNet structure. ImageNet aims to populate the majority of the 80,000 synsets of WordNet with an average of 500–1000 clean and full resolution images. This will result in tens of millions of annotated images organized by the semantic hierarchy of WordNet. This paper offers a detailed analysis of ImageNet in its current state: 12 subtrees with 5247 synsets and 3.2 million images in total. We show that ImageNet is much larger in scale and diversity and much more accurate than the current image datasets. Constructing such a large-scale database is a challenging task. We describe the data collection scheme with Amazon Mechanical Turk. Lastly, we illustrate the usefulness of ImageNet through three simple applications in object recognition, image classification and automatic object clustering. We hope that the scale, accuracy, diversity and hierarchical structure of ImageNet can offer unparalleled opportunities to researchers in the computer vision community and beyond.',\n",
       " 'A fast and elitist multiobjective genetic algorithm: NSGA-II': 'Multi-objective evolutionary algorithms (MOEAs) that use non-dominated sorting and sharing have been criticized mainly for: (1) their O(MN/sup 3/) computational complexity (where M is the number of objectives and N is the population size); (2) their non-elitism approach; and (3) the need to specify a sharing parameter. In this paper, we suggest a non-dominated sorting-based MOEA, called NSGA-II (Non-dominated Sorting Genetic Algorithm II), which alleviates all of the above three difficulties. Specifically, a fast non-dominated sorting approach with O(MN/sup 2/) computational complexity is presented. Also, a selection operator is presented that creates a mating pool by combining the parent and offspring populations and selecting the best N solutions (with respect to fitness and spread). Simulation results on difficult test problems show that NSGA-II is able, for most problems, to find a much better spread of solutions and better convergence near the true Pareto-optimal front compared to the Pareto-archived evolution strategy and the strength-Pareto evolutionary algorithm - two other elitist MOEAs that pay special attention to creating a diverse Pareto-optimal front. Moreover, we modify the definition of dominance in order to solve constrained multi-objective problems efficiently. Simulation results of the constrained NSGA-II on a number of test problems, including a five-objective, seven-constraint nonlinear problem, are compared with another constrained multi-objective optimizer, and the much better performance of NSGA-II is observed.',\n",
       " 'Particle swarm optimization': 'A concept for the optimization of nonlinear functions using particle swarm methodology is introduced. The evolution of several paradigms is outlined, and an implementation of one of the paradigms is discussed. Benchmark testing of the paradigm is described, and applications, including nonlinear function optimization and neural network training, are proposed. The relationships between particle swarm optimization and both artificial life and genetic algorithms are described.',\n",
       " 'Going deeper with convolutions': 'We propose a deep convolutional neural network architecture codenamed Inception that achieves the new state of the art for classification and detection in the ImageNet Large-Scale Visual Recognition Challenge 2014 (ILSVRC14). The main hallmark of this architecture is the improved utilization of the computing resources inside the network. By a carefully crafted design, we increased the depth and width of the network while keeping the computational budget constant. To optimize quality, the architectural decisions were based on the Hebbian principle and the intuition of multi-scale processing. One particular incarnation used in our submission for ILSVRC14 is called GoogLeNet, a 22 layers deep network, the quality of which is assessed in the context of classification and detection.',\n",
       " 'You Only Look Once: Unified, Real-Time Object Detection': 'We present YOLO, a new approach to object detection. Prior work on object detection repurposes classifiers to perform detection. Instead, we frame object detection as a regression problem to spatially separated bounding boxes and associated class probabilities. A single neural network predicts bounding boxes and class probabilities directly from full images in one evaluation. Since the whole detection pipeline is a single network, it can be optimized end-to-end directly on detection performance. Our unified architecture is extremely fast. Our base YOLO model processes images in real-time at 45 frames per second. A smaller version of the network, Fast YOLO, processes an astounding 155 frames per second while still achieving double the mAP of other real-time detectors. Compared to state-of-the-art detection systems, YOLO makes more localization errors but is less likely to predict false positives on background. Finally, YOLO learns very general representations of objects. It outperforms other detection methods, including DPM and R-CNN, when generalizing from natural images to other domains like artwork.'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstracts_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_csv(publications_dict, abstract_dict):\n",
    "    rows = []\n",
    "    for title, details in publications_dict.items():\n",
    "        rows.append({\n",
    "            'Title': title,\n",
    "            'Author': ', '.join(details[1]),\n",
    "            'Abstract': abstract_dict.get(title, ''),  # Use the get method to avoid KeyError\n",
    "            'Year': details[2],\n",
    "            'Journal/Conference Name': details[3],\n",
    "            'Conference or Journal': details[4],\n",
    "            'Publisher': details[5]\n",
    "    })\n",
    "    df = pd.DataFrame(rows)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = dict_to_csv(titles_and_info, abstracts_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Year</th>\n",
       "      <th>Journal/Conference Name</th>\n",
       "      <th>Conference or Journal</th>\n",
       "      <th>Publisher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Deep Residual Learning for Image Recognition</td>\n",
       "      <td>Shaoqing Ren, Xiangyu Zhang, Kaiming He, Jian Sun</td>\n",
       "      <td>Deeper neural networks are more difficult to t...</td>\n",
       "      <td>2016</td>\n",
       "      <td>2016 IEEE Conference on Computer Vision and Pa...</td>\n",
       "      <td>Conference Paper</td>\n",
       "      <td>IEEE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A mathematical theory of communication</td>\n",
       "      <td>C. E. Shannon</td>\n",
       "      <td>The recent development of various methods of m...</td>\n",
       "      <td>1948</td>\n",
       "      <td>The Bell System Technical Journal</td>\n",
       "      <td>Journal Article</td>\n",
       "      <td>Nokia Bell Labs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A new look at the statistical model identifica...</td>\n",
       "      <td>H. Akaike</td>\n",
       "      <td>The history of the development of statistical ...</td>\n",
       "      <td>1974</td>\n",
       "      <td>IEEE Transactions on Automatic Control</td>\n",
       "      <td>Journal Article</td>\n",
       "      <td>IEEE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Image quality assessment: from error visibilit...</td>\n",
       "      <td>E.P. Simoncelli, Zhou Wang, H.R. Sheikh, A.C. ...</td>\n",
       "      <td>Objective methods for assessing perceptual ima...</td>\n",
       "      <td>2004</td>\n",
       "      <td>IEEE Transactions on Image Processing</td>\n",
       "      <td>Journal Article</td>\n",
       "      <td>IEEE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gradient-based learning applied to document re...</td>\n",
       "      <td>L. Bottou, Y. Bengio, P. Haffner, Y. Lecun</td>\n",
       "      <td>Multilayer neural networks trained with the ba...</td>\n",
       "      <td>1998</td>\n",
       "      <td>Proceedings of the IEEE</td>\n",
       "      <td>Journal Article</td>\n",
       "      <td>IEEE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ImageNet: A large-scale hierarchical image dat...</td>\n",
       "      <td>Wei Dong, Kai Li, Richard Socher, Li-Jia Li, L...</td>\n",
       "      <td>The explosion of image data on the Internet ha...</td>\n",
       "      <td>2009</td>\n",
       "      <td>2009 IEEE Conference on Computer Vision and Pa...</td>\n",
       "      <td>Conference Paper</td>\n",
       "      <td>IEEE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A fast and elitist multiobjective genetic algo...</td>\n",
       "      <td>K. Deb, T. Meyarivan, A. Pratap, S. Agarwal</td>\n",
       "      <td>Multi-objective evolutionary algorithms (MOEAs...</td>\n",
       "      <td>2002</td>\n",
       "      <td>IEEE Transactions on Evolutionary Computation</td>\n",
       "      <td>Journal Article</td>\n",
       "      <td>IEEE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Particle swarm optimization</td>\n",
       "      <td>J. Kennedy, R. Eberhart</td>\n",
       "      <td>A concept for the optimization of nonlinear fu...</td>\n",
       "      <td>1995</td>\n",
       "      <td>Proceedings of ICNN'95 - International Confere...</td>\n",
       "      <td>Conference Paper</td>\n",
       "      <td>IEEE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Going deeper with convolutions</td>\n",
       "      <td>Dumitru Erhan, Yangqing Jia, Scott Reed, Andre...</td>\n",
       "      <td>We propose a deep convolutional neural network...</td>\n",
       "      <td>2015</td>\n",
       "      <td>2015 IEEE Conference on Computer Vision and Pa...</td>\n",
       "      <td>Conference Paper</td>\n",
       "      <td>IEEE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>You Only Look Once: Unified, Real-Time Object ...</td>\n",
       "      <td>Joseph Redmon, Ross Girshick, Santosh Divvala,...</td>\n",
       "      <td>We present YOLO, a new approach to object dete...</td>\n",
       "      <td>2016</td>\n",
       "      <td>2016 IEEE Conference on Computer Vision and Pa...</td>\n",
       "      <td>Conference Paper</td>\n",
       "      <td>IEEE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0       Deep Residual Learning for Image Recognition   \n",
       "1             A mathematical theory of communication   \n",
       "2  A new look at the statistical model identifica...   \n",
       "3  Image quality assessment: from error visibilit...   \n",
       "4  Gradient-based learning applied to document re...   \n",
       "5  ImageNet: A large-scale hierarchical image dat...   \n",
       "6  A fast and elitist multiobjective genetic algo...   \n",
       "7                        Particle swarm optimization   \n",
       "8                     Going deeper with convolutions   \n",
       "9  You Only Look Once: Unified, Real-Time Object ...   \n",
       "\n",
       "                                              Author  \\\n",
       "0  Shaoqing Ren, Xiangyu Zhang, Kaiming He, Jian Sun   \n",
       "1                                      C. E. Shannon   \n",
       "2                                          H. Akaike   \n",
       "3  E.P. Simoncelli, Zhou Wang, H.R. Sheikh, A.C. ...   \n",
       "4         L. Bottou, Y. Bengio, P. Haffner, Y. Lecun   \n",
       "5  Wei Dong, Kai Li, Richard Socher, Li-Jia Li, L...   \n",
       "6        K. Deb, T. Meyarivan, A. Pratap, S. Agarwal   \n",
       "7                            J. Kennedy, R. Eberhart   \n",
       "8  Dumitru Erhan, Yangqing Jia, Scott Reed, Andre...   \n",
       "9  Joseph Redmon, Ross Girshick, Santosh Divvala,...   \n",
       "\n",
       "                                            Abstract  Year  \\\n",
       "0  Deeper neural networks are more difficult to t...  2016   \n",
       "1  The recent development of various methods of m...  1948   \n",
       "2  The history of the development of statistical ...  1974   \n",
       "3  Objective methods for assessing perceptual ima...  2004   \n",
       "4  Multilayer neural networks trained with the ba...  1998   \n",
       "5  The explosion of image data on the Internet ha...  2009   \n",
       "6  Multi-objective evolutionary algorithms (MOEAs...  2002   \n",
       "7  A concept for the optimization of nonlinear fu...  1995   \n",
       "8  We propose a deep convolutional neural network...  2015   \n",
       "9  We present YOLO, a new approach to object dete...  2016   \n",
       "\n",
       "                             Journal/Conference Name Conference or Journal  \\\n",
       "0  2016 IEEE Conference on Computer Vision and Pa...      Conference Paper   \n",
       "1                  The Bell System Technical Journal       Journal Article   \n",
       "2             IEEE Transactions on Automatic Control       Journal Article   \n",
       "3              IEEE Transactions on Image Processing       Journal Article   \n",
       "4                            Proceedings of the IEEE       Journal Article   \n",
       "5  2009 IEEE Conference on Computer Vision and Pa...      Conference Paper   \n",
       "6      IEEE Transactions on Evolutionary Computation       Journal Article   \n",
       "7  Proceedings of ICNN'95 - International Confere...      Conference Paper   \n",
       "8  2015 IEEE Conference on Computer Vision and Pa...      Conference Paper   \n",
       "9  2016 IEEE Conference on Computer Vision and Pa...      Conference Paper   \n",
       "\n",
       "         Publisher  \n",
       "0             IEEE  \n",
       "1  Nokia Bell Labs  \n",
       "2             IEEE  \n",
       "3             IEEE  \n",
       "4             IEEE  \n",
       "5             IEEE  \n",
       "6             IEEE  \n",
       "7             IEEE  \n",
       "8             IEEE  \n",
       "9             IEEE  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('publications_with_abstracts.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
